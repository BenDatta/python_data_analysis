from datetime import datetime, timedelta

import pandas as pd
from airflow import DAG
from airflow.decorators import task


default_args = {
    "owner": "analytics_team",
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
}

with DAG(
    dag_id="bank_customers_churn",
    start_date=datetime(2023, 11, 12),
    schedule="@daily",
    catchup=False,
    default_args=default_args,
    tags=["engineering"],
) as dag:

    @task
    def extract_data():
        base_path = "/tmp/bank_churn"
        file_path = (
            "/Users/benjamin/Documents/GitHub/python_data_analysis/projects/data engineering/"
            "data/bank_churn/Bank_Churn_all_data.xlsx"
        )
        
        customer_path = f"{base_path}/customer.parquet"
        acc_path = f"{base_path}/account.parquet"

        pd.read_excel(
            file_path, sheet_name="Customer_Info", engine="openpyxl"
        ).to_parquet(customer_path)

        pd.read_excel(
            file_path, sheet_name="Account_Info", engine="openpyxl"
        ).to_parquet(acc_path)

        return {"customer_path": customer_path, "acc_path": acc_path}

    @task
    def transform(data_dict):
        customer = data_dict["customer"]
        acc_info = data_dict["acc_info"]

        bank_churn = customer.merge(
            acc_info, how="inner", on="CustomerId"
        ).drop_duplicates()
        bank_churn["Geography"] = bank_churn["Geography"].replace(
            {"FRA": "France", "French": "France"}
        )
        bank_churn["Age"] = (
            pd.to_numeric(bank_churn["Age"], errors="coerce").fillna(0).astype(int)
        )

        bank_churn["Balance"] = bank_churn["Balance"].replace("â‚¬", "", regex=True)
        bank_churn["Balance"] = (
            pd.to_numeric(bank_churn["Balance"], errors="coerce")
            .fillna(0)
            .astype(float)
        )

        if "Tenure_y" in bank_churn.columns:
            bank_churn = bank_churn.rename(columns={"Tenure_y": "Tenure"})
            bank_churn.drop(columns="Tenure_x", errors="ignore", inplace=True)

        bank_churn.dropna(subset=["Surname"], inplace=True)
        return bank_churn

    @task
    def dim_customer(bank_churn):
        dim_cust = (
            bank_churn[["CustomerId", "Surname", "Age", "Gender"]]
            .copy()
            .reset_index(drop=True)
        )
        dim_cust["Customer_key"] = dim_cust.index + 1
        return dim_cust

    @task
    def dim_country(bank_churn):
        dim_count = bank_churn[["Geography"]].drop_duplicates().reset_index(drop=True)
        dim_count["Country_key"] = dim_count.index + 1
        return dim_count

    @task
    def fact_bank_transactions(bank_churn, dim_cust, dim_count):
        fact = bank_churn.merge(
            dim_cust[["CustomerId", "Customer_key"]], on="CustomerId"
        )
        fact = fact.merge(dim_count[["Geography", "Country_key"]], on="Geography")

        return fact[
            [
                "Customer_key",
                "Country_key",
                "CreditScore",
                "Balance",
                "NumOfProducts",
                "HasCrCard",
                "Tenure",
                "IsActiveMember",
                "EstimatedSalary",
                "Exited",
            ]
        ]

    # Pipeline Flow
    raw_data = extract_data()
    clean_df = transform(raw_data)

    cust_df = dim_customer(clean_df)
    country_df = dim_country(clean_df)

    fact_bank_transactions(clean_df, cust_df, country_df)
